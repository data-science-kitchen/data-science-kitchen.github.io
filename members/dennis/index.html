<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Data Science Kitchen


  | Dennis

</title>
<meta name="description" content="Data Science Kitchen - Machine learning, delivered fresh from the oven!
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/members/dennis/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<meta name="google-site-verification" content="dAD0JNDfv-jJbgdvDjnHJiw8dc5a7LKucPt2hcDhPPU" />


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-186875845-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-186875845-2');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       Data Science Kitchen
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/members/">
                members
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <nav aria-label="breadcrumb">
  <ol class="breadcrumb p-0 text-lowercase">
    <li class="breadcrumb-item"><a href="/">home</a></li>
    <li class="breadcrumb-item"><a href="/members">members</a></li>
    <li class="breadcrumb-item active">Dennis</li>
  </ol>
</nav>

<div class="text-center row m-0" style="width: 100%;">
  <div class="col-sm-12 p-0" text-center>
    <img class="rounded-circle" src="/assets/img/dennis.jpg" style="width:30%">
  </div>
  <div class="col-sm-12 p-0 text-center">
    <br/>
    <h1>Dennis <span class="font-weight-bold">Orth</span></h1>
  </div>
  <div class="col-sm-12 p-0 text-center">
    <span class="navbar-brand social fa-2x">
      
        <a href="mailto:dennis [dot] orth [at] data-science-kitchen [dot] de"><i class="fa fa-envelope-square"></i></a>
      
      
      
      
      
      
      
      
    </span>
    <br/><br/>
  </div>  
</div>

<div class="container-fluid p-0 text-justify">
  <h1 class="title mb-4 p-0">in a nutshell</h1>
  <p>tbd</p>


</div>


<div class="container-fluid p-0 text-justify">
  <h1 class="title mb-4 p-0">publications</h1>
  <div class="publications">
    
      <h2 class="year">2021</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
    
    <abbr class="badge">KONVENS</abbr>
    
  
  </div>-->

  <div id="DSK2021a" class="col-sm-12">
    
      <div class="title">Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Niclas Hildebrandt,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Benedikt BÃ¶nninghoff,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Christopher Schymura
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Konferenz zur Verarbeitung natÃ¼rlicher Sprache/Conference on Natural Language Processing (KONVENS)</em>
      
      <!--
        , 2021
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://netlibrary.aau.at/obvukloa/content/pageview/6435304" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers. Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme. Our best submission achieved macro-averaged F1-scores of 66.8%, 69.9% and 72.5% for the identification of toxic, engaging, and fact-claiming comments.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2020</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Heckmann2020" class="col-sm-12">
    
      <div class="title">Method for Assisting a Driver of an Ego-Vehicle in Making Use of a Gap Between Vehicles, Corresponding Driver Assistance System and Vehicle Equipped with such Driving Assistance System</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Martin Heckmann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>United States Patent Application 20200160077</em>
      
      <!--
        , 2020
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A method for assisting a driver of an ego-vehicle in making use of a gap between vehicles to enter a traffic flow at an intersection is suggested, comprising the following method steps: First, other vehicles in the environment of the ego-vehicle are physically sensed using at least one environment sensor mounted on the ego-vehicle. Second, a gap size of at least one gap between two successive vehicles are calculated in a processor based on the sensor's/sensors' output. An ego-vehicle driver's gazing behavior using at least one driver sensor mounted on the ego-vehicle is observed and analyzed and an assistance signal is generated based on the result of the analysis and the determined size of the at least one gap. Finally, a recommendation or warning perceivable for the ego-vehicle's driver is output in accordance with the assistance signal.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2019</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Heckmann2019" class="col-sm-12">
    
      <div class="title">CORA, a prototype for a cooperative speech-based on-demand intersection assistant</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Martin Heckmann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mark Dunn,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nico Steinhardt,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bram Bolder,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 11th International Conference on Automotive User Interfaces and Interactive Vehicular Applications Adjunct Proceedings - AutomotiveUI '19</em>
      
      <!--
        , 2019
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://dl.acm.org/doi/10.1145/3349263.3349599" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the first speech-based advanced driver assistance prototype. It is based on our previously proposed on-demand communication concept for the interaction between the driver and his or her vehicle. Using this concept, drivers can flexibly activate the system via speech whenever they want to receive assistance. We could show via driver simulator studies that an instantiation of this concept as an intersection assistant, supporting the driver in turning left, was well received by drivers and preferred to an alternative, vision-based system. In this paper, we present a prototype implementation and give details on how we adapted it to the intricacy of urban traffic as well as to the shortcomings of current sensor technology in establishing an adequate environment perception. The accompanying video gives an impression of the interaction between the driver and the system when cooperatively turning left from a subordinate road into crossing traffic.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2018</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Orth" class="col-sm-12">
    
      <div class="title">A Speech-Based On-Demand Intersection Assistant Prototype</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bram Bolder,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nico Steinhardt,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mark Dunn,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Martin Heckmann
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Intelligent Vehicles Symposium (IV)</em>
      
      <!--
        , 2018
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/8500402" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We have recently proposed a speech-based on- demand intersection assistant which helps the driver to handle urban intersections by informing him of the traffic situation on the right hand side and recommending suitable gaps in traffic. In a previous user study, conducted in a simulator, we could show that the system is in general well accepted and preferred by drivers compared to driving without assistance or with only visual support. In this paper, we report on an implementation of this system and its evaluation in real urban traffic. We use LIDAR sensors for the perception of the traffic environment. A scene analyzer estimates the gaps between the vehicles in real time. The result of this analysis is provided to a dialog manager, which uses it to inform the driver of approaching vehicles and suitable gaps. While approaching the intersection, the driver can activate the system via a wake-up-word and control it with subsequent speech commands. The design of the data analyzer and dialog manager is based on evaluations at real intersections. The resulting system can provide suitable support to the driver in a wide range of traffic situations.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Orth2018" class="col-sm-12">
    
      <div class="title">Analysis of a Speech-Based Intersection Assistant in Real Urban Traffic</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nico Steinhardt,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bram Bolder,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Mark Dunn,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Martin Heckmann
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE International Conference on Intelligent Transportation Systems (ITSC)</em>
      
      <!--
        , 2018
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/8569821" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Previously, we have presented a speech-based intersection assistant prototype. The system is activated on-demand by the driver and gives afterwards, via speech, information on suitable gaps between the traffic vehicles approaching from the right. It is comparable to a front seat passenger which helps in the maneuver decision for an intended turn left. This system has assumed a more or less constant flow of the traffic. To also handle situations of more dynamic urban traffic, including vehicles that may be slowing down or stopping, we have now extended our previous approach by a dynamic vehicle model. This model predicts the future traffic vehicle state based on second-order vehicle dynamics. We perform an in depth analysis of our system on a set of recordings under various traffic conditions. In this analysis we compare in particular the previous and the novel vehicle model. Both approaches lead to a correct recommendation in approximately 90% of the cases. Unexpectedly, the dynamic model does not lead to significant improvements in the system behavior, despite its increased accuracy.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Acl2018" class="col-sm-12">
    
      <div class="title">"Gap After the Next Two Vehicles": A Spatio-temporally Situated Dialog for a Cooperative Driving Assistant</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Martin Heckmann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Speech Communication; 13th ITG-Symposium</em>
      
      <!--
        , 2018
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/8578048" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present a spatio-temporally situated dialog that is implemented in a driver assistance system. The system supports the driver in turning left at a busy urban intersection by providing verbal information on the vehicles arriving from the right. This is a highly dynamic scenario, as the location of the vehicles significantly changes while the system is referring to them. Consequently, the time the system needs for producing the utterances and the time drivers need to comprehend them and prepare their action has to be taken into account in the dialog management. We introduce a dialog concept, which predicts the future traffic participants state and plans the utterances such that they align with the driver's expectations. We have implemented and evaluated this system in a prototype vehicle.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2017</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Orth2017b" class="col-sm-12">
    
      <div class="title">Benefits of Personalization in the Context of a Speech-Based Left-Turn Assistant</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nadja Sch{\"{o}}mig,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Christian Mark,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Monika Jagiellowicz-Kaufmann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Martin Heckmann
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 9th International Conference on Automotive User Interfaces and Interactive Vehicular Applications - AutomotiveUI '17</em>
      
      <!--
        , 2017
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://www.honda-ri.de/pubs/pdf/3499.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We have previously introduced a novel Assistance On Demand (AOD) concept in the context of an urban speech-based left-turn assistant which supports the driver in monitoring and decision making by providing recommendations for suitable time gaps to enter the intersection. In a first user study participants showed a clear preference for the AOD system, yet also frequently mentioned that the recommended gaps did not fit their driving behavior. In the user study we present here, we investigate in how far the acceptance and efficiency of the AOD system can be increased by a personalization of the recommended gaps to the individual driver. For this purpose, we estimate individual driversâ€™ gap acceptance from observations of their manual driving and use it to evaluate a default and a personalized variant of the AOD system. Results reveal a clear preference for the personalized assistant compared to the default one and to driving manually.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Orth2017a" class="col-sm-12">
    
      <div class="title">Predicting Driver Left-Turn Behavior from Few Training Samples using a Maximum A-Posteriori Method</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Martin Heckmann
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE International Conference on Intelligent Transportation Systems (ITSC)</em>
      
      <!--
        , 2017
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/8317721" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this work, we introduce a novel maximum a posteriori (MAP) method, which can predict driver left-turn behavior from only a few training samples. For the prediction of the driver behavior in this scenario we utilize the so-called critical gap. It signifies how large a gap minimally has to be for the driver to accept it and take the turn. The latter is especially important for the personalization of an intersection assistant, which we are currently developing. In contrast to Troutbeck's critical gap estimation method, we define a likelihood over all observable accepted and rejected gaps, thus we provide a model that does not require the driver to behave consistently. Subsequently, we extend it to a MAP estimation by incorporating prior knowledge of the critical gap. Using this approach, we obtain a maximum prediction error of 13.8% if only one training sample is used, which is a relative improvement of 35.2% compared to Troutbeck's method.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Orth2017c" class="col-sm-12">
    
      <div class="title">A Maximum Likelihood Method for Driver-Specific Critical-Gap Estimation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Milton Sarria Paja,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kersten Schaller,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Andreas Pech,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Martin Heckmann
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Intelligent Vehicles Symposium (IV)</em>
      
      <!--
        , 2017
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/7995776" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this work, we introduce a maximum likelihood (ML) method to estimate the smallest accepted gap of a specific driver, the so-called critical gap. Previous methods, like Troutbeck's or Raff's method, are well known and widely used but require a consistently behaving driver, which is usually not met. The methods will be investigated for the personalization of an intersection assistant, which we are currently developing. We start with the hypothesis that the size that constitutes an acceptable gap is driver-dependent. To test this hypothesis, we have performed a simulator study with 9 participants. The results reveal that there is a significant inter-individual difference in the critical gap between the drivers, as postulated. Next we investigate how well we can predict which gap the driver will take when we use the previously estimated personalized critical gap versus a driver independent one. Using the personalized gap compared to a driver independent one reduces the error from 11.8 % to 9 8 %. These results are a clear indication that personalization can be utilized to increase the effectiveness and usability of an intersection assistant.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="Heckmann2017" class="col-sm-12">
    
      <div class="title">Development of a personalised intersection assistant</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Martin Heckmann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Dennis Orth</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Heiko Wersing,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ATZ worldwide</em>
      
      <!--
        , 2017
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://ipg-automotive.com/fileadmin/user_upload/content/Download/PDF/Articles/1705_ATZworldwide_HondaResearchInstitute_Development_of_a_Personalised_Intersection_Assistant_EN.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Advanced driver assistance systems have great potential to significantly improve the safety and comfort of driving. Honda Research Institute Europe and Ruhr University Bochum show how personalisation could improve the acceptance and impact of driver assistance functions by using an intuitive and speech-based intersection assistant.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
  </div>
</div>


    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Data Science Kitchen.
    <br />Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
    <a href="/imprint/">Impressum</a>.
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
