<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Data Science Kitchen


  | Benedikt

</title>
<meta name="description" content="Data Science Kitchen - Machine learning, delivered fresh from the oven!
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üî•</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/members/benedikt/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<meta name="google-site-verification" content="dAD0JNDfv-jJbgdvDjnHJiw8dc5a7LKucPt2hcDhPPU" />


<!-- Theming-->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-186875845-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-186875845-2');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       Data Science Kitchen
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/members/">
                members
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <nav aria-label="breadcrumb">
  <ol class="breadcrumb p-0 text-lowercase">
    <li class="breadcrumb-item"><a href="/">home</a></li>
    <li class="breadcrumb-item"><a href="/members">members</a></li>
    <li class="breadcrumb-item active">Benedikt</li>
  </ol>
</nav>

<div class="text-center row m-0" style="width: 100%;">
  <div class="col-sm-12 p-0" text-center>
    <img class="rounded-circle" src="/assets/img/lord.png" style="width:30%">
  </div>
  <div class="col-sm-12 p-0 text-center">
    <br/>
    <h1>Benedikt <span class="font-weight-bold">B√∂nninghoff</span></h1>
  </div>
  <div class="col-sm-12 p-0 text-center">
    <span class="navbar-brand social fa-2x">
      
        <a href="mailto:benedikt [dot] boeninghoff [at] data-science-kitchen [dot] de"><i class="fa fa-envelope-square"></i></a>
      
      
      
      
        <a href="https://www.linkedin.com/in/benedikt-tobias-boenninghoff-a95b4a14b" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
      
      
        <a href="https://www.github.com/boenninghoff" target="_blank" title="GitHub"><i class="fab fa-github-square"></i></a>
      
      
      
        <a href="https://www.researchgate.net/profile/Benedikt-Boenninghoff/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate-square"></i></a>
      
      
    </span>
    <br/><br/>
  </div>  
</div>

<div class="container-fluid p-0 text-justify">
  <h1 class="title mb-4 p-0">in a nutshell</h1>
  <p>Benedikt Boenninghoff received a B.S. degree in IT security and a M.S. degree in communications engineering from the <a href="https://etit.ruhr-uni-bochum.de/" target="_blank">Ruhr University Bochum</a>, Germany, in 2014 and 2017, respectively. Since 2017, he is a member of the <a href="https://cognitive-signal-processing.de/" target="_blank">Cognitive Signal Processing Group</a> at the Ruhr University Bochum, where he is pursuing a Ph.D. degree in hybrid neural-probabilistic authorship analysis. His research interests include speech signal processing, machine/deep learning and natural language processing.</p>


</div>


<div class="container-fluid p-0 text-justify">
  <h1 class="title mb-4 p-0">publications</h1>
  <div class="publications">
    
      <h2 class="year">2021</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
    
    <abbr class="badge">KONVENS</abbr>
    
  
  </div>-->

  <div id="DSK2021a" class="col-sm-12">
    
      <div class="title">Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Niclas Hildebrandt,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dennis Orth,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Christopher Schymura
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Konferenz zur Verarbeitung nat√ºrlicher Sprache/Conference on Natural Language Processing (KONVENS)</em>
      
      <!--
        , 2021
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://netlibrary.aau.at/obvukloa/content/pageview/6435304" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers. Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme. Our best submission achieved macro-averaged F1-scores of 66.8%, 69.9% and 72.5% for the identification of toxic, engaging, and fact-claiming comments.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="boenninghoff:2021b" class="col-sm-12">
    
      <div class="title">O2D2: Out-Of-Distribution Detector to Capture Undecidable Trials in Authorship Verification (1st place at PAN@CLEF 2021 Authorship Identification Challenge)</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Robert M. Nickel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>CLEF 2021 Labs and Workshops, Notebook Papers</em>
      
      <!--
        , 2021
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2106.15825.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The PAN 2021 authorship verification (AV) challenge is part of a three-year strategy, moving from a cross-topic/closed-set AV task to a cross-topic/open-set AV task over a collection of fanfiction texts. In this work, we present a novel hybrid neural-probabilistic framework that is designed to tackle the challenges of the 2021 task. Our system is based on our 2020 winning submission, with updates to significantly reduce sensitivities to topical variations and to further improve the system's calibration by means of an uncertainty-adaptation layer. Our framework additionally includes an out-of-distribution detector (O2D2) for defining non-responses. Our proposed system outperformed all other systems that participated in the PAN 2021 AV task.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="boenninghoff:2021a" class="col-sm-12">
    
      <div class="title">Self-Calibrating Neural-Probabilistic Model for Authorship Verification Under Covariate Shift</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Robert M. Nickel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>12th International Conference of the CLEF Association (CLEF 2021)</em>
      
      <!--
        , 2021
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2106.11196.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We are addressing two fundamental problems in authorship verification (AV): Topic variability and miscalibration. Variations in the topic of two disputed texts are a major cause of error for most AV systems. In addition, it is observed that the underlying probability estimates produced by deep learning AV mechanisms oftentimes do not match the actual case counts in the respective training data. As such, probability estimates are poorly calibrated. We are expanding our framework from PAN 2020 to include Bayes factor scoring (BFS) and an uncertainty adaptation layer (UAL) to address both problems. Experiments with the 2020/21 PAN AV shared task data show that the proposed method significantly reduces sensitivities to topical variations and significantly improves the system's calibration.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
    
    <abbr class="badge">INTERSPEECH</abbr>
    
  
  </div>-->

  <div id="Schymura2021" class="col-sm-12">
    
      <div class="title">PILOT: Introducing Transformers for Probabilistic Sound Event Localization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Christopher Schymura,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tsubasa Ochiai,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Marc Delcroix,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Keisuke Kinoshita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tomohiro Nakatani,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shoko Araki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Annual Conference of the International Speech Communication Association (INTERSPEECH)</em>
      
      <!--
        , 2021
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2106.03903" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sound event localization aims at estimating the positions of sound sources in the environment with respect to an acoustic receiver (e.g. a microphone array). Recent advances in this domain most prominently focused on utilizing deep recurrent neural networks. Inspired by the success of transformer architectures as a suitable alternative to classical recurrent neural networks, this paper introduces a novel transformer-based sound event localization framework, where temporal dependencies in the received multi-channel audio signals are captured via self-attention mechanisms. Additionally, the estimated sound event positions are represented as multivariate Gaussian variables, yielding an additional notion of uncertainty, which many previously proposed deep learning-based systems designed for this application do not provide. The framework is evaluated on three publicly available multi-source sound event localization datasets and compared against state-of-the-art methods in terms of localization error and event detection accuracy. It outperforms all competing systems on all datasets with statistical significant differences in performance.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICASSP</abbr>
    
  
  </div>-->

  <div id="Wissing2021" class="col-sm-12">
    
      <div class="title">Data Fusion for Audiovisual Speaker Localization: Extending Dynamic Stream Weights to the Spatial Domain</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Julio Wissing,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tsubasa Ochiai,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Marc Delcroix,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Keisuke Kinoshita,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tomohiro Nakatani,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shoko Araki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Christopher Schymura
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>
      
      <!--
        , 2021
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2102.11588" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/document/9413399" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/rub-ksv/spatial-stream-weights" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Estimating the positions of multiple speakers can be helpful for tasks like automatic speech recognition or speaker diarization. Both applications benefit from a known speaker position when, for instance, applying beamforming or assigning unique speaker identities. Recently, several approaches utilizing acoustic signals augmented with visual data have been proposed for this task. However, both the acoustic and the visual modality may be corrupted in specific spatial regions, for instance due to poor lighting conditions or to the presence of background noise. This paper proposes a novel audiovisual data fusion framework for speaker localization by assigning individual dynamic stream weights to specific regions in the localization space. This fusion is achieved via a neural network, which combines the predictions of individual audio and video trackers based on their time- and location-dependent reliability. A performance evaluation using audiovisual recordings yields promising results, with the proposed fusion approach outperforming all baseline models.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2020</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="boenninghoff-etal-2020-variational" class="col-sm-12">
    
      <div class="title">Variational Autoencoder with Embedded Student-t Mixture Model for Authorship Attribution</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Steffen Zeiler,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Robert Nickel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 28th International Conference on Computational Linguistics (COLING)</em>
      
      <!--
        , 2020
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2005.13930.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Traditional computational authorship attribution describes a classification task in a closed-set scenario. Given a finite set of candidate authors and corresponding labeled texts, the objective is to determine which of the authors has written another set of anonymous or disputed texts. In this work, we propose a probabilistic autoencoding framework to deal with this supervised classification task. Variational autoencoders (VAEs) have had tremendous success in learning latent representations. However, existing VAEs are currently still bound by limitations imposed by the assumed Gaussianity of the underlying probability distributions in the latent space. In this work, we are extending a VAE with an embedded Gaussian mixture model to a Student-t mixture model, which allows for an independent control of the {``}heaviness{''} of the respective tails of the implied probability densities. Experiments over an Amazon review dataset indicate superior performance of the proposed method.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="boenninghoff:2020" class="col-sm-12">
    
      <div class="title">Deep Bayes Factor Scoring for Authorship Verification (1st place at PAN@CLEF 2020 Authorship Identification Challenge)</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Julian Rupp,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Robert M. Nickel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>CLEF 2020 Labs and Workshops, Notebook Papers</em>
      
      <!--
        , 2020
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2008.10105.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The PAN 2020 authorship verification (AV) challenge focuses on a cross-topic/closed-set AV task over a collection of fanfiction texts. Fanfiction is a fan-written extension of a storyline in which a so-called fandom topic describes the principal subject of the document. The data provided in the PAN 2020 AV task is quite challenging because authors of texts across multiple/different fandom topics are included. In this work, we present a hierarchical fusion of two well-known approaches into a single end-to-end learning procedure: A deep metric learning framework at the bottom aims to learn a pseudo-metric that maps a document of variable length onto a fixed-sized feature vector. At the top, we incorporate a probabilistic layer to perform Bayes factor scoring in the learned metric space. We also provide text preprocessing strategies to deal with the cross-topic issue.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2019</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="9005650" class="col-sm-12">
    
      <div class="title">Autorschaftsanalyse- Verstellungsstrategien und M√∂glichkeiten der automatisierten Erkennung</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Steffen Hessler,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kerstin Kucharczik,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Robert M. Nickel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Karin Pittner
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Datenschutz und Datensicherheit - DuD</em>
      
      <!--
        , 2019
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://link.springer.com/article/10.1007/s11623-019-1191-6" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Der Austausch von Informationen findet zunehmend √ºber soziale Medien und Online-Nachrichtendienstestatt. Daraus kann ein hohes Schadenspotential erwachsen, wenn es gelingt, f√ºr kriminelle Absichteneine andere Identit√§t vorzut√§uschen oder im Schutze der Anonymit√§t Fake News bzw. Hate Speechzu verbreiten. Zum Schutz vor solchen Angriffen untersucht die Forensische Linguistik Textsammlungen hinsichtlichder Urheberschaft und m√∂glicher biographischer Aussagen. Doch der Umfang der √ºber das Internetver√∂ffentlichten Daten verlangt automatisierte Verfahren, die die Analyse unterst√ºtzen.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="9005651" class="col-sm-12">
    
      <div class="title">Explainable Authorship Verification in Social Media via Attention-based Similarity Learning</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Steffen Hessler,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorothea Kolossa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Robert M. Nickel
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>2019 IEEE International Conference on Big Data (Big Data)</em>
      
      <!--
        , 2019
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/1910.08144.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Authorship verification is the task of analyzing the linguistic patterns of two or more texts to determine whether they were written by the same author or not. The analysis is traditionally performed by experts who consider linguistic features, which include spelling mistakes, grammatical inconsistencies, and stylistics for example. Machine learning algorithms, on the other hand, can be trained to accomplish the same, but have traditionally relied on so-called stylometric features. The disadvantage of such features is that their reliability is greatly diminished for short and topically varied social media texts. In this interdisciplinary work, we propose a substantial extension of a recently published hierarchical Siamese neural network approach, with which it is feasible to learn neural features and to visualize the decision-making process. For this purpose, a new large-scale corpus of short Amazon reviews for text comparison research is compiled and we show that the Siamese network topologies outperform state-of-the-art approaches that were built up on stylometric features. Our linguistic analysis of the internal attention weights of the network shows that the proposed method is indeed able to latch on to some traditional linguistic categories. </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li>
<li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="8683405" class="col-sm-12">
    
      <div class="title">Similarity Learning for Authorship Verification in Social Media</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Robert M. Nickel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Steffen Zeiler,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>
      
      <!--
        , 2019
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/1908.07844.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Authorship verification tries to answer the question if two documents with unknown authors were written by the same author or not. A range of successful technical approaches has been proposed for this task, many of which are based on traditional linguistic features such as n-grams. These algorithms achieve good results for certain types of written documents like books and novels. Forensic authorship verification for social media, however, is a much more challenging task since messages tend to be relatively short, with a large variety of different genres and topics. At this point, traditional methods based on features like n-grams have had limited success. In this work, we propose a new neural network topology for similarity learning that significantly improves the performance on the author verification task with such challenging data sets. </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2017</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="glarner17_interspeech" class="col-sm-12">
    
      <div class="title">Leveraging Text Data for Word Segmentation for Underresourced Languages</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Thomas Glarner,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Oliver Walter,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Reinhold Haeb-Umbach
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proc. Interspeech 2017</em>
      
      <!--
        , 2017
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2017/glarner17_interspeech.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this contribution we show how to exploit text data to support word discovery from audio input in an underresourced target language. Given audio, of which a certain amount is transcribed at the word level, and additional unrelated text data, the approach is able to learn a probabilistic mapping from acoustic units to characters and utilize it to segment the audio data into words without the need of a pronunciation dictionary. This is achieved by three components: an unsupervised acoustic unit discovery system, a supervisedly trained acoustic unit-to-grapheme converter, and a word discovery system, which is initialized with a language model trained on the text data. Experiments for multiple setups show that the initialization of the language model with text data improves the word segmentation performance by a large margin.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
      <h2 class="year">2016</h2>
      <ol class="bibliography"><li><div class="row">
  <!--<div class="col-sm-2 abbr">
  
  </div>-->

  <div id="7776144" class="col-sm-12">
    
      <div class="title">Unsupervised Classification of Voiced Speech and Pitch Tracking Using Forward-Backward Kalman Filtering</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Benedikt B√∂nninghoff</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Robert M. Nickel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Steffen Zeiler,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Dorothea Kolossa
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Speech Communication; 12. ITG Symposium</em>
      
      <!--
        , 2016
      -->
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="https://arxiv.org/pdf/2103.01173.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The detection of voiced speech, the estimation of the fundamental frequency, and the tracking of pitch values over time are crucial subtasks for a variety of speech processing techniques. Many different algorithms have been developed for each of the three subtasks. We present a new algorithm that integrates the three subtasks into a single procedure. The algorithm can be applied to pre-recorded speech utterances in the presence of considerable amounts of background noise. We combine a collection of standard metrics, such as the zero-crossing rate, for example, to formulate an unsupervised voicing classifier. The estimation of pitch values is accomplished with a hybrid autocorrelation-based technique. We propose a forward-backward Kalman filter to smooth the estimated pitch contour. In experiments, we are able to show that the proposed method compares favorably with current, state-of-the-art pitch detection algorithms. </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>

</li></ol>
    
  </div>
</div>


    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Data Science Kitchen.
    <br />Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
    <a href="/imprint/">Impressum</a>.
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
